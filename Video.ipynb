{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "# Load the main video (VideoCapture 0 usually refers to the webcam on a computer)\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Load the second video\n",
    "cap2 = cv2.VideoCapture('Test.mp4')\n",
    "\n",
    "pressed_k = False\n",
    "while True:\n",
    "    # Read the main video\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Display the main video\n",
    "    cv2.imshow('Main Video', frame)\n",
    "\n",
    "    # Get the key press\n",
    "    key = cv2.waitKey(1) & 0xFF\n",
    "    if(key == ord('k')):\n",
    "         cap2.release()\n",
    "         cap2 = cv2.VideoCapture('Test.mp4')\n",
    "         \n",
    "    ret2, frame2 = cap2.read()\n",
    "    if not ret2:\n",
    "            # Reset the capture if the video has ended\n",
    "            cap2.set(cv2.CAP_PROP_POS_FRAMES, 0)\n",
    "            continue\n",
    "    cv2.imshow('Second Video', frame2)\n",
    "\n",
    "    # Quit if 'q' is pressed\n",
    "    if key == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release the video captures\n",
    "cap.release()\n",
    "cap2.release()\n",
    "\n",
    "# Close all OpenCV windows\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import ttk\n",
    "\n",
    "def open_window():\n",
    "    # Create a new Tkinter window\n",
    "    window = tk.Tk()\n",
    "    window.title(\"Tkinter Window\")\n",
    "\n",
    "    # Create the notebook (tabs container)\n",
    "    notebook = ttk.Notebook(window)\n",
    "\n",
    "    # Create frames for each tab\n",
    "    frame1 = ttk.Frame(notebook)\n",
    "    frame2 = ttk.Frame(notebook)\n",
    "    frame3 = ttk.Frame(notebook)\n",
    "\n",
    "    # Add frames to notebook\n",
    "    notebook.add(frame1, text=\"Tab 1\")\n",
    "    notebook.add(frame2, text=\"Tab 2\")\n",
    "    notebook.add(frame3, text=\"Tab 3\")\n",
    "\n",
    "    # Add content to tabs\n",
    "    label1 = tk.Label(frame1, text=\"This is Tab 1\")\n",
    "    label1.pack()\n",
    "    label2 = tk.Label(frame2, text=\"This is Tab 2\")\n",
    "    label2.pack()\n",
    "    label3 = tk.Label(frame3, text=\"This is Tab 3\")\n",
    "    label3.pack()\n",
    "\n",
    "    # Pack the notebook\n",
    "    notebook.pack(expand=True, fill='both')\n",
    "\n",
    "    # Run the window's main loop\n",
    "    window.mainloop()\n",
    "\n",
    "# Call the function to open the window\n",
    "open_window()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from dtw import dtw\n",
    "import cv2\n",
    "from fastdtw import fastdtw\n",
    "from scipy.spatial.distance import euclidean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Starting point\n",
    "with open('Gestures.csv', mode='w', newline='') as file:\n",
    "      writer = csv.writer(file)\n",
    "      starting_row = ['label' , 'trajectory']\n",
    "      writer.writerow(starting_row)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def Training_classify_traj(ex_name):\n",
    "\n",
    "    lower_bound = (31, 60, 87)\n",
    "    upper_bound = (61, 255, 219)\n",
    "\n",
    "    lower_bound = (169 , 148 , 92)\n",
    "    upper_bound = (179 , 255 ,255)\n",
    "    object_track = False\n",
    "    cap = cv2.VideoCapture(0)  # Start video capture\n",
    "    trajectory_points = []\n",
    "    count = 0\n",
    "    while True:\n",
    "        count += 1\n",
    "        if(count == 80):\n",
    "            break\n",
    "        ret, frame = cap.read()  # Read frame from the camera\n",
    "        frame = cv2.flip(frame, 1)\n",
    "        if ret:  # If frame read successful\n",
    "            # Convert image color to HSV (easier for color detection)\n",
    "            hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "            # Create a binary image where white pixels are those within the color range\n",
    "            mask = cv2.inRange(hsv, lower_bound, upper_bound)\n",
    "\n",
    "            # Find the contours of the binary image\n",
    "            contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "            # Filter contours based on area\n",
    "            filtered_contours = [cnt for cnt in contours if cv2.contourArea(cnt) > 100]\n",
    "\n",
    "            if filtered_contours:\n",
    "                largest_contour = max(filtered_contours, key=cv2.contourArea)\n",
    "                object_track = True\n",
    "                # Get the coordinates of the center of the largest contour\n",
    "                M = cv2.moments(largest_contour)\n",
    "                if M[\"m00\"] != 0:\n",
    "                    cX = int(M[\"m10\"] / M[\"m00\"])\n",
    "                    cY = int(M[\"m01\"] / M[\"m00\"])\n",
    "                    trajectory_points.append((cX,cY))\n",
    "                else:\n",
    "                    cX, cY = 0, 0\n",
    "\n",
    "                # Draw the center of the shape on the image\n",
    "                cv2.circle(frame, (cX, cY), 7, (255, 255, 255), -1)\n",
    "                cv2.putText(frame, \"center\", (cX - 20, cY - 20), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2)\n",
    "            else:\n",
    "                if(object_track == True):\n",
    "                    print(object_track)\n",
    "                object_track = False\n",
    "                \n",
    "            # Display frame\n",
    "            cv2.imshow(\"Frame\", frame)\n",
    "\n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'):  # Quit if 'q' is pressed\n",
    "                break\n",
    "\n",
    "        else:\n",
    "            break\n",
    "\n",
    "\n",
    "    cap.release()  # Release video capture\n",
    "    cv2.destroyAllWindows()  # Close all OpenCV windows\n",
    "\n",
    "    with open('Gestures.csv', mode='a', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        traj = json.dumps(trajectory_points)\n",
    "        row = [ex_name , traj]\n",
    "        #writer.writerow(row)\n",
    "\n",
    "Training_classify_traj('Start_2')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Left_1': array([[ 82, 207],\n",
      "       [ 80, 207],\n",
      "       [ 80, 207],\n",
      "       [ 80, 207],\n",
      "       [ 80, 207],\n",
      "       [ 80, 209],\n",
      "       [ 80, 209],\n",
      "       [ 80, 209],\n",
      "       [ 80, 209],\n",
      "       [ 80, 210],\n",
      "       [ 80, 210],\n",
      "       [ 80, 210],\n",
      "       [ 80, 210],\n",
      "       [115, 216],\n",
      "       [115, 216],\n",
      "       [115, 216],\n",
      "       [115, 216],\n",
      "       [172, 219],\n",
      "       [172, 219],\n",
      "       [172, 219],\n",
      "       [172, 219],\n",
      "       [224, 246],\n",
      "       [224, 246],\n",
      "       [224, 246],\n",
      "       [224, 246],\n",
      "       [274, 242],\n",
      "       [274, 242],\n",
      "       [274, 242],\n",
      "       [274, 242],\n",
      "       [313, 237],\n",
      "       [313, 237],\n",
      "       [313, 237],\n",
      "       [313, 237],\n",
      "       [353, 225],\n",
      "       [353, 225],\n",
      "       [353, 225],\n",
      "       [353, 225],\n",
      "       [396, 219],\n",
      "       [396, 219],\n",
      "       [396, 219],\n",
      "       [396, 219],\n",
      "       [449, 208],\n",
      "       [449, 208],\n",
      "       [449, 208],\n",
      "       [449, 208],\n",
      "       [474, 193],\n",
      "       [474, 193],\n",
      "       [474, 193],\n",
      "       [474, 193],\n",
      "       [486, 169],\n",
      "       [486, 169],\n",
      "       [486, 169],\n",
      "       [486, 169],\n",
      "       [492, 171],\n",
      "       [492, 171],\n",
      "       [492, 171],\n",
      "       [492, 171]]), 'Right_1': array([[240, 389],\n",
      "       [236, 384],\n",
      "       [236, 384],\n",
      "       [236, 384],\n",
      "       [236, 384],\n",
      "       [232, 380],\n",
      "       [232, 380],\n",
      "       [232, 380],\n",
      "       [232, 380],\n",
      "       [230, 375],\n",
      "       [230, 375],\n",
      "       [230, 375],\n",
      "       [230, 375],\n",
      "       [228, 375],\n",
      "       [228, 375],\n",
      "       [228, 375],\n",
      "       [228, 375],\n",
      "       [285, 352],\n",
      "       [285, 352],\n",
      "       [285, 352],\n",
      "       [285, 352],\n",
      "       [305, 303],\n",
      "       [305, 303],\n",
      "       [305, 303],\n",
      "       [305, 303],\n",
      "       [241, 212],\n",
      "       [241, 212],\n",
      "       [241, 212],\n",
      "       [241, 212],\n",
      "       [158, 164],\n",
      "       [158, 164],\n",
      "       [158, 164],\n",
      "       [158, 164],\n",
      "       [ 89, 193],\n",
      "       [ 89, 193],\n",
      "       [ 89, 193],\n",
      "       [ 89, 193],\n",
      "       [ 72, 336],\n",
      "       [ 72, 336],\n",
      "       [ 72, 336],\n",
      "       [ 72, 336],\n",
      "       [213, 369],\n",
      "       [213, 369],\n",
      "       [213, 369],\n",
      "       [213, 369],\n",
      "       [284, 320],\n",
      "       [284, 320],\n",
      "       [284, 320],\n",
      "       [284, 320],\n",
      "       [247, 233],\n",
      "       [247, 233],\n",
      "       [247, 233],\n",
      "       [247, 233],\n",
      "       [201, 184],\n",
      "       [201, 184],\n",
      "       [201, 184],\n",
      "       [201, 184],\n",
      "       [170, 179],\n",
      "       [170, 179]]), 'Start_1': array([[276, 181],\n",
      "       [267, 162],\n",
      "       [267, 162],\n",
      "       [267, 162],\n",
      "       [267, 162],\n",
      "       [270, 163],\n",
      "       [270, 163],\n",
      "       [270, 163],\n",
      "       [270, 163],\n",
      "       [275, 166],\n",
      "       [275, 166],\n",
      "       [275, 166],\n",
      "       [275, 166],\n",
      "       [282, 163],\n",
      "       [282, 163],\n",
      "       [282, 163],\n",
      "       [282, 163],\n",
      "       [261, 144],\n",
      "       [261, 144],\n",
      "       [261, 144],\n",
      "       [261, 144],\n",
      "       [190, 111],\n",
      "       [190, 111],\n",
      "       [190, 111],\n",
      "       [190, 111],\n",
      "       [163, 159],\n",
      "       [163, 159],\n",
      "       [163, 159],\n",
      "       [163, 159],\n",
      "       [253, 295],\n",
      "       [253, 295],\n",
      "       [253, 295],\n",
      "       [253, 295],\n",
      "       [265, 382],\n",
      "       [265, 382],\n",
      "       [265, 382],\n",
      "       [265, 382],\n",
      "       [179, 443],\n",
      "       [179, 443],\n",
      "       [179, 443],\n",
      "       [179, 443],\n",
      "       [134, 374],\n",
      "       [134, 374],\n",
      "       [134, 374],\n",
      "       [134, 374],\n",
      "       [166, 312],\n",
      "       [166, 312],\n",
      "       [166, 312],\n",
      "       [166, 312],\n",
      "       [180, 312],\n",
      "       [180, 312],\n",
      "       [180, 312],\n",
      "       [180, 312],\n",
      "       [168, 309],\n",
      "       [168, 309],\n",
      "       [168, 309],\n",
      "       [168, 309],\n",
      "       [164, 305],\n",
      "       [164, 305]])}\n"
     ]
    }
   ],
   "source": [
    "#Reading Phase\n",
    "traj_info = pd.read_csv('Gestures.csv')\n",
    "map_traj = {}\n",
    "for index, row in traj_info.iterrows():\n",
    "      label = str(row['label'])\n",
    "      trajectories = eval(row['trajectory'])\n",
    "      trajectories = np.array(trajectories)\n",
    "      map_traj[label] = trajectories\n",
    "print(map_traj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Left_1\n",
      "[(82, 207), stroke None, (80, 207), stroke None, (80, 207), stroke None, (80, 207), stroke None, (80, 207), stroke None, (80, 209), stroke None, (80, 209), stroke None, (80, 209), stroke None, (80, 209), stroke None, (80, 210), stroke None, (80, 210), stroke None, (80, 210), stroke None, (80, 210), stroke None, (115, 216), stroke None, (115, 216), stroke None, (115, 216), stroke None, (115, 216), stroke None, (172, 219), stroke None, (172, 219), stroke None, (172, 219), stroke None, (172, 219), stroke None, (224, 246), stroke None, (224, 246), stroke None, (224, 246), stroke None, (224, 246), stroke None, (274, 242), stroke None, (274, 242), stroke None, (274, 242), stroke None, (274, 242), stroke None, (313, 237), stroke None, (313, 237), stroke None, (313, 237), stroke None, (313, 237), stroke None, (353, 225), stroke None, (353, 225), stroke None, (353, 225), stroke None, (353, 225), stroke None, (396, 219), stroke None, (396, 219), stroke None, (396, 219), stroke None, (396, 219), stroke None, (449, 208), stroke None, (449, 208), stroke None, (449, 208), stroke None, (449, 208), stroke None, (474, 193), stroke None, (474, 193), stroke None, (474, 193), stroke None, (474, 193), stroke None, (486, 169), stroke None, (486, 169), stroke None, (486, 169), stroke None, (486, 169), stroke None, (492, 171), stroke None, (492, 171), stroke None, (492, 171), stroke None, (492, 171), stroke None]\n",
      "Right_1\n",
      "[(240, 389), stroke None, (236, 384), stroke None, (236, 384), stroke None, (236, 384), stroke None, (236, 384), stroke None, (232, 380), stroke None, (232, 380), stroke None, (232, 380), stroke None, (232, 380), stroke None, (230, 375), stroke None, (230, 375), stroke None, (230, 375), stroke None, (230, 375), stroke None, (228, 375), stroke None, (228, 375), stroke None, (228, 375), stroke None, (228, 375), stroke None, (285, 352), stroke None, (285, 352), stroke None, (285, 352), stroke None, (285, 352), stroke None, (305, 303), stroke None, (305, 303), stroke None, (305, 303), stroke None, (305, 303), stroke None, (241, 212), stroke None, (241, 212), stroke None, (241, 212), stroke None, (241, 212), stroke None, (158, 164), stroke None, (158, 164), stroke None, (158, 164), stroke None, (158, 164), stroke None, (89, 193), stroke None, (89, 193), stroke None, (89, 193), stroke None, (89, 193), stroke None, (72, 336), stroke None, (72, 336), stroke None, (72, 336), stroke None, (72, 336), stroke None, (213, 369), stroke None, (213, 369), stroke None, (213, 369), stroke None, (213, 369), stroke None, (284, 320), stroke None, (284, 320), stroke None, (284, 320), stroke None, (284, 320), stroke None, (247, 233), stroke None, (247, 233), stroke None, (247, 233), stroke None, (247, 233), stroke None, (201, 184), stroke None, (201, 184), stroke None, (201, 184), stroke None, (201, 184), stroke None, (170, 179), stroke None, (170, 179), stroke None]\n",
      "Start_1\n",
      "[(276, 181), stroke None, (267, 162), stroke None, (267, 162), stroke None, (267, 162), stroke None, (267, 162), stroke None, (270, 163), stroke None, (270, 163), stroke None, (270, 163), stroke None, (270, 163), stroke None, (275, 166), stroke None, (275, 166), stroke None, (275, 166), stroke None, (275, 166), stroke None, (282, 163), stroke None, (282, 163), stroke None, (282, 163), stroke None, (282, 163), stroke None, (261, 144), stroke None, (261, 144), stroke None, (261, 144), stroke None, (261, 144), stroke None, (190, 111), stroke None, (190, 111), stroke None, (190, 111), stroke None, (190, 111), stroke None, (163, 159), stroke None, (163, 159), stroke None, (163, 159), stroke None, (163, 159), stroke None, (253, 295), stroke None, (253, 295), stroke None, (253, 295), stroke None, (253, 295), stroke None, (265, 382), stroke None, (265, 382), stroke None, (265, 382), stroke None, (265, 382), stroke None, (179, 443), stroke None, (179, 443), stroke None, (179, 443), stroke None, (179, 443), stroke None, (134, 374), stroke None, (134, 374), stroke None, (134, 374), stroke None, (134, 374), stroke None, (166, 312), stroke None, (166, 312), stroke None, (166, 312), stroke None, (166, 312), stroke None, (180, 312), stroke None, (180, 312), stroke None, (180, 312), stroke None, (180, 312), stroke None, (168, 309), stroke None, (168, 309), stroke None, (168, 309), stroke None, (168, 309), stroke None, (164, 305), stroke None, (164, 305), stroke None]\n"
     ]
    }
   ],
   "source": [
    "from dollarpy import Recognizer, Template, Point\n",
    "trajectories_to_classify = [[6,4],[1,2]]\n",
    "def classify(Temp , tc):\n",
    "    min_distance = float('inf')\n",
    "    class_label = None\n",
    "    for traj in Temp:\n",
    "      distance, path = fastdtw(tc, Temp[traj] , dist=euclidean)\n",
    "      if(distance < min_distance):\n",
    "         min_distance = distance\n",
    "         class_label = traj\n",
    "    return min_distance , class_label\n",
    "\n",
    "def dollar_Templates():\n",
    "  Templates_dollar_py = []\n",
    "  for k in map_traj:\n",
    "    curr_traj = map_traj[k]\n",
    "    L = []\n",
    "    for c in curr_traj:\n",
    "        p = Point(c[0] , c[1])\n",
    "        L.append(p)\n",
    "    print(k)\n",
    "    print(L)\n",
    "    template_dpy = Template(k , L)\n",
    "    Templates_dollar_py.append(template_dpy)\n",
    "  return Templates_dollar_py\n",
    "temps = dollar_Templates()\n",
    "recognizer = Recognizer(temps)\n",
    "   \n",
    "#classify(Template , trajectories_to_classify)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Start_1', 0.3019019872291987)\n",
      "('Left_1', 0.33540158783473417)\n",
      "('Start_1', 0.29674873896622367)\n",
      "('Left_1', 0.40995351695049687)\n",
      "('Start_1', 0.022637948337813407)\n",
      "('Right_1', 0.2333152473912674)\n",
      "(None, 0)\n",
      "('Right_1', 0.11445276456974285)\n",
      "('Left_1', 0.32513025814803587)\n",
      "('Start_1', 0.27974140510199474)\n",
      "('Left_1', 0.18939131240163365)\n",
      "('Left_1', 0.08407830115773773)\n",
      "('Right_1', 0.048349690898084274)\n",
      "('Right_1', 0.21832255347399232)\n",
      "(None, 0)\n",
      "(None, 0)\n",
      "(None, 0)\n",
      "(None, 0)\n",
      "('Start_1', 0.18084242206564738)\n",
      "('Left_1', 0.539130930004864)\n"
     ]
    }
   ],
   "source": [
    "def Test_Trajectory(Temp):\n",
    "    lower_bound = np.array([155, 50, 50])\n",
    "    upper_bound = np.array([175, 255, 255])\n",
    "\n",
    "  \n",
    "    object_track = False\n",
    "    cap = cv2.VideoCapture(0)  # Start video capture\n",
    "    trajectory_points = []\n",
    "    trajectory_points_dp = []\n",
    "    count = 0\n",
    "    while True:\n",
    "        count += 1\n",
    "        if(count % 80 == 0):\n",
    "            if trajectory_points_dp:\n",
    "                result = recognizer.recognize(trajectory_points_dp)\n",
    "                trajectory_points_dp = []\n",
    "                print(result)\n",
    "            \n",
    "            \n",
    "        ret, frame = cap.read()  # Read frame from the camera\n",
    "        frame = cv2.flip(frame, 1)\n",
    "        if ret:  # If frame read successful\n",
    "            # Convert image color to HSV (easier for color detection)\n",
    "            hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "            # Create a binary image where white pixels are those within the color range\n",
    "            mask = cv2.inRange(hsv, lower_bound, upper_bound)\n",
    "\n",
    "            # Find the contours of the binary image\n",
    "            contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "            # Filter contours based on area\n",
    "            filtered_contours = [cnt for cnt in contours if cv2.contourArea(cnt) > 1000]\n",
    "\n",
    "            if filtered_contours:\n",
    "                # Get the largest contour\n",
    "                largest_contour = max(filtered_contours, key=cv2.contourArea)\n",
    "                object_track = True\n",
    "                # Get the coordinates of the center of the largest contour\n",
    "                M = cv2.moments(largest_contour)\n",
    "                if M[\"m00\"] != 0:\n",
    "                    cX = int(M[\"m10\"] / M[\"m00\"])\n",
    "                    cY = int(M[\"m01\"] / M[\"m00\"])\n",
    "                    trajectory_points.append((cX,cY))\n",
    "                    trajectory_points_dp.append(Point(cX , cY))\n",
    "                else:\n",
    "                     cX, cY = 0, 0\n",
    "\n",
    "                # Draw the center of the shape on the image\n",
    "                cv2.circle(frame, (cX, cY), 7, (255, 255, 255), -1)\n",
    "                cv2.putText(frame, \"center\", (cX - 20, cY - 20), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2)\n",
    "            \n",
    "                \n",
    "            # Display frame\n",
    "            cv2.imshow(\"Frame\", frame)\n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'):  # Quit if 'q' is pressed\n",
    "                break\n",
    "\n",
    "        else:\n",
    "            break\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "Test_Trajectory(map_traj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('left_2', 0.3696272812350322)\n",
      "('left_1', 0.5807411137686531)\n",
      "('right_2', 0.32295478019449597)\n",
      "('right_2', 0.1263593447222784)\n",
      "('right_2', 0.26707090979021253)\n",
      "('left_1', 0.5568588597747904)\n",
      "('left_1', 0.8223358447106035)\n",
      "('left_2', 0.005003643989261342)\n",
      "(None, 0)\n",
      "(None, 0)\n",
      "('Start_2', 0.029042380597822604)\n",
      "(None, 0)\n",
      "(None, 0)\n",
      "('right_1', 0.021401661430474284)\n",
      "(None, 0)\n",
      "('left_2', 0.4914467459705194)\n",
      "(None, 0)\n",
      "('Start_2', 0.000610463490223534)\n",
      "('left_1', 0.21439816253854238)\n",
      "('Start_2', 0.10107444819098177)\n"
     ]
    }
   ],
   "source": [
    "def Test_Trajectory(Temp):\n",
    "    lower_bound = np.array([155, 50, 50])\n",
    "    upper_bound = np.array([175, 255, 255])\n",
    "    object_track = False\n",
    "    cap = cv2.VideoCapture(0)  # Start video capture\n",
    "    trajectory_points = []\n",
    "    trajectory_points_dp = []\n",
    "    count = 0\n",
    "    while True:\n",
    "        count += 1\n",
    "        if(count % 50 == 0):\n",
    "            if trajectory_points_dp:\n",
    "               result = recognizer.recognize(trajectory_points_dp) \n",
    "               print(result)\n",
    "            trajectory_points = []\n",
    "            trajectory_points_dp = []\n",
    "            \n",
    "        ret, frame = cap.read()  # Read frame from the camera\n",
    "        frame = cv2.flip(frame, 1)\n",
    "        if ret:  # If frame read successful\n",
    "            # Convert image color to HSV (easier for color detection)\n",
    "            hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "            # Create a binary image where white pixels are those within the color range\n",
    "            mask = cv2.inRange(hsv, lower_bound, upper_bound)\n",
    "\n",
    "            # Find the contours of the binary image\n",
    "            contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "            # Filter contours based on area\n",
    "            filtered_contours = [cnt for cnt in contours if cv2.contourArea(cnt) > 1000]\n",
    "\n",
    "            if filtered_contours:\n",
    "                # Get the largest contour\n",
    "                largest_contour = max(filtered_contours, key=cv2.contourArea)\n",
    "                object_track = True\n",
    "                # Get the coordinates of the center of the largest contour\n",
    "                M = cv2.moments(largest_contour)\n",
    "                if M[\"m00\"] != 0:\n",
    "                    cX = int(M[\"m10\"] / M[\"m00\"])\n",
    "                    cY = int(M[\"m01\"] / M[\"m00\"])\n",
    "                    trajectory_points.append((cX,cY))\n",
    "                    trajectory_points_dp.append(Point(cX , cY, 1))\n",
    "                else:\n",
    "                     cX, cY = 0, 0\n",
    "\n",
    "                # Draw the center of the shape on the image\n",
    "                cv2.circle(frame, (cX, cY), 7, (255, 255, 255), -1)\n",
    "                cv2.putText(frame, \"center\", (cX - 20, cY - 20), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2)\n",
    "               \n",
    "                \n",
    "            # Display frame\n",
    "            cv2.imshow(\"Frame\", frame)\n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'):  # Quit if 'q' is pressed\n",
    "                break\n",
    "\n",
    "        else:\n",
    "            break\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "Test_Trajectory(map_traj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average color in BGR format: [ 85.57081769 153.98664998 168.39945766]\n",
      "Average color in HSV format: [ 23.25917814 128.48779725 173.58562787]\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Global variables\n",
    "rectangle = False   # True if the left mouse button is DOWN\n",
    "ix, iy = -1, -1     # Initial mouse click position\n",
    "fx, fy = -1, -1     # Final mouse release position\n",
    "\n",
    "# Mouse callback function\n",
    "def draw_rectangle(event, x, y, flags, param):\n",
    "    global rectangle, ix, iy, fx, fy\n",
    "\n",
    "    if event == cv2.EVENT_LBUTTONDOWN:   # When the left mouse button is clicked DOWN\n",
    "        rectangle = True\n",
    "        ix, iy = x, y\n",
    "\n",
    "    elif event == cv2.EVENT_MOUSEMOVE:   # When the mouse is MOVING\n",
    "        if rectangle == True:    # If the left button is DOWN (dragging the mouse)\n",
    "            fx, fy = x, y\n",
    "            cv2.rectangle(img, (ix, iy), (fx, fy), (0, 255, 0), 1)\n",
    "\n",
    "    elif event == cv2.EVENT_LBUTTONUP:   # When the left mouse button is released UP\n",
    "        rectangle = False\n",
    "        fx, fy = x, y\n",
    "        cv2.rectangle(img, (ix, iy), (fx, fy), (0, 255, 0), 1)\n",
    "\n",
    "        # Here we can get the ROI and compute the average color\n",
    "        roi = img[iy:fy, ix:fx]\n",
    "        avg_color_per_row = np.average(roi, axis=0)\n",
    "        avg_color = np.average(avg_color_per_row, axis=0)\n",
    "        print(f'Average color in BGR format: {avg_color}')\n",
    "\n",
    "        # Convert ROI from BGR to HSV\n",
    "        roi_hsv = cv2.cvtColor(roi, cv2.COLOR_BGR2HSV)\n",
    "        avg_color_per_row_hsv = np.average(roi_hsv, axis=0)\n",
    "        avg_color_hsv = np.average(avg_color_per_row_hsv, axis=0)\n",
    "        print(f'Average color in HSV format: {avg_color_hsv}')\n",
    "\n",
    "\n",
    "# Create a black image and a window\n",
    "img = np.zeros((512, 512, 3), np.uint8)\n",
    "cv2.namedWindow('image')\n",
    "\n",
    "# Bind the draw_rectangle function to mouse cliks and movement\n",
    "cv2.setMouseCallback('image', draw_rectangle)\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    ret, img = cap.read()  # Capture frame from the camera\n",
    "\n",
    "    # Show the image in an OpenCV window\n",
    "    cv2.imshow('image', img)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):  # Quit if 'q' is pressed\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27.0\n",
      "27.0\n",
      "27.0\n",
      "27.0\n",
      "30.0\n",
      "30.0\n",
      "30.0\n",
      "30.0\n",
      "150.0\n",
      "150.0\n",
      "150.0\n",
      "150.0\n",
      "821.0\n",
      "821.0\n",
      "821.0\n",
      "821.0\n",
      "584.5\n",
      "584.5\n",
      "584.5\n",
      "584.5\n",
      "1374.5\n",
      "1374.5\n",
      "1374.5\n",
      "1374.5\n",
      "1875.0\n",
      "1875.0\n",
      "1875.0\n",
      "1875.0\n",
      "2004.5\n",
      "2004.5\n",
      "2004.5\n",
      "2004.5\n",
      "3136.0\n",
      "3136.0\n",
      "3136.0\n",
      "3136.0\n",
      "3979.5\n",
      "3979.5\n",
      "3979.5\n",
      "3979.5\n",
      "5218.0\n",
      "5218.0\n",
      "5218.0\n",
      "5218.0\n",
      "9856.5\n",
      "9856.5\n",
      "9856.5\n",
      "9856.5\n",
      "9763.5\n",
      "9763.5\n",
      "9763.5\n",
      "9763.5\n",
      "9799.5\n",
      "9799.5\n",
      "9799.5\n",
      "9799.5\n",
      "10374.5\n",
      "10374.5\n",
      "10374.5\n",
      "10374.5\n",
      "9695.0\n",
      "9695.0\n",
      "9695.0\n",
      "9695.0\n",
      "10068.5\n",
      "10068.5\n",
      "10068.5\n",
      "10068.5\n",
      "9965.5\n",
      "9965.5\n",
      "9965.5\n",
      "9965.5\n",
      "9664.5\n",
      "9664.5\n",
      "9664.5\n",
      "9664.5\n",
      "8855.0\n",
      "8855.0\n",
      "8855.0\n",
      "8855.0\n",
      "7484.0\n",
      "7484.0\n",
      "7484.0\n",
      "7484.0\n",
      "5834.0\n",
      "5834.0\n",
      "5834.0\n",
      "5834.0\n",
      "4956.5\n",
      "4956.5\n",
      "4956.5\n",
      "4956.5\n",
      "2679.0\n",
      "2679.0\n",
      "2679.0\n",
      "2679.0\n",
      "2882.0\n",
      "2882.0\n",
      "2882.0\n",
      "2882.0\n",
      "4901.5\n",
      "4901.5\n",
      "4901.5\n",
      "4901.5\n",
      "6921.0\n",
      "6921.0\n",
      "6921.0\n",
      "6921.0\n",
      "8274.0\n",
      "8274.0\n",
      "8274.0\n",
      "8274.0\n",
      "8159.0\n",
      "8159.0\n",
      "8159.0\n",
      "8159.0\n",
      "7879.0\n",
      "7879.0\n",
      "7879.0\n",
      "7879.0\n",
      "4772.5\n",
      "4772.5\n",
      "4772.5\n",
      "4772.5\n",
      "7451.0\n",
      "7451.0\n",
      "7451.0\n",
      "7451.0\n",
      "7021.0\n",
      "7021.0\n",
      "7021.0\n",
      "7021.0\n",
      "6642.5\n",
      "6642.5\n",
      "6642.5\n",
      "6642.5\n",
      "4132.5\n",
      "4132.5\n",
      "4132.5\n",
      "4132.5\n",
      "7287.0\n",
      "7287.0\n",
      "7287.0\n",
      "7287.0\n",
      "7792.0\n",
      "7792.0\n",
      "7792.0\n",
      "7792.0\n",
      "6877.5\n",
      "6877.5\n",
      "6877.5\n",
      "6877.5\n",
      "6948.5\n",
      "6948.5\n",
      "6948.5\n",
      "6948.5\n",
      "6256.0\n",
      "6256.0\n",
      "6256.0\n",
      "6256.0\n",
      "93.0\n",
      "93.0\n",
      "93.0\n",
      "93.0\n",
      "17.5\n",
      "17.5\n",
      "17.5\n",
      "17.5\n",
      "17.5\n",
      "17.5\n",
      "17.5\n",
      "17.5\n",
      "42.0\n",
      "42.0\n",
      "42.0\n",
      "42.0\n",
      "16.0\n",
      "16.0\n",
      "16.0\n",
      "16.0\n",
      "53.0\n",
      "53.0\n",
      "53.0\n",
      "53.0\n",
      "48.0\n",
      "48.0\n",
      "48.0\n",
      "48.0\n",
      "52.0\n",
      "52.0\n",
      "52.0\n",
      "52.0\n",
      "235.0\n",
      "235.0\n",
      "235.0\n",
      "235.0\n",
      "157.5\n",
      "157.5\n",
      "157.5\n",
      "157.5\n",
      "44.0\n",
      "44.0\n",
      "44.0\n",
      "44.0\n",
      "20.0\n",
      "20.0\n",
      "20.0\n",
      "20.0\n",
      "40.0\n",
      "40.0\n",
      "40.0\n",
      "40.0\n",
      "97.5\n",
      "97.5\n",
      "97.5\n",
      "97.5\n",
      "16.0\n",
      "16.0\n",
      "16.0\n",
      "16.0\n",
      "29.5\n",
      "29.5\n",
      "29.5\n",
      "29.5\n",
      "34.0\n",
      "34.0\n",
      "34.0\n",
      "34.0\n",
      "348.5\n",
      "348.5\n",
      "348.5\n",
      "348.5\n",
      "573.0\n",
      "573.0\n",
      "573.0\n",
      "573.0\n",
      "503.0\n",
      "503.0\n",
      "503.0\n",
      "503.0\n",
      "554.5\n",
      "554.5\n",
      "554.5\n",
      "554.5\n",
      "735.5\n",
      "735.5\n",
      "735.5\n",
      "735.5\n",
      "626.5\n",
      "626.5\n",
      "626.5\n",
      "626.5\n",
      "1026.5\n",
      "1026.5\n",
      "1026.5\n",
      "1026.5\n",
      "1540.0\n",
      "1540.0\n",
      "1540.0\n",
      "1540.0\n",
      "1875.5\n",
      "1875.5\n",
      "1875.5\n",
      "1875.5\n",
      "2337.0\n",
      "2337.0\n",
      "2337.0\n",
      "2337.0\n",
      "2566.5\n",
      "2566.5\n",
      "2566.5\n",
      "2566.5\n",
      "2038.0\n",
      "2038.0\n",
      "2038.0\n",
      "2038.0\n",
      "1742.5\n",
      "1742.5\n",
      "1742.5\n",
      "1742.5\n",
      "1224.5\n",
      "1224.5\n",
      "1224.5\n",
      "1224.5\n",
      "133.5\n",
      "133.5\n",
      "133.5\n",
      "133.5\n",
      "28.5\n",
      "28.5\n",
      "28.5\n",
      "28.5\n",
      "38.5\n",
      "38.5\n",
      "38.5\n",
      "38.5\n",
      "16.0\n",
      "16.0\n",
      "16.0\n",
      "16.0\n",
      "8.0\n",
      "8.0\n",
      "8.0\n",
      "8.0\n",
      "30.5\n",
      "30.5\n",
      "30.5\n",
      "30.5\n",
      "34.5\n",
      "34.5\n",
      "34.5\n",
      "34.5\n",
      "59.5\n",
      "59.5\n",
      "59.5\n",
      "59.5\n",
      "12.0\n",
      "12.0\n",
      "12.0\n",
      "12.0\n",
      "21.0\n",
      "21.0\n",
      "21.0\n",
      "21.0\n",
      "18.5\n",
      "18.5\n",
      "18.5\n",
      "18.5\n",
      "24.5\n",
      "24.5\n",
      "24.5\n",
      "16.0\n",
      "16.0\n",
      "16.0\n",
      "16.0\n",
      "82.0\n",
      "82.0\n",
      "82.0\n",
      "88.0\n",
      "88.0\n",
      "88.0\n",
      "88.0\n",
      "12.0\n",
      "12.0\n",
      "67.0\n",
      "67.0\n",
      "67.0\n",
      "57.5\n",
      "57.5\n",
      "57.5\n",
      "57.5\n",
      "64.5\n",
      "64.5\n",
      "177.5\n",
      "177.5\n",
      "177.5\n",
      "179.5\n",
      "179.5\n",
      "179.5\n",
      "179.5\n",
      "51.0\n",
      "51.0\n",
      "79.5\n",
      "79.5\n",
      "79.5\n",
      "35.5\n",
      "35.5\n",
      "35.5\n",
      "35.5\n",
      "52.5\n",
      "52.5\n",
      "31.5\n",
      "31.5\n",
      "31.5\n",
      "38.5\n",
      "38.5\n",
      "38.5\n",
      "38.5\n",
      "8.0\n",
      "8.0\n",
      "73.5\n",
      "73.5\n",
      "73.5\n",
      "8.0\n",
      "8.0\n",
      "8.0\n",
      "8.0\n",
      "16.0\n",
      "16.0\n",
      "55.5\n",
      "55.5\n",
      "55.5\n",
      "35.5\n",
      "35.5\n",
      "35.5\n",
      "35.5\n",
      "33.0\n",
      "33.0\n",
      "77.0\n",
      "77.0\n",
      "77.0\n",
      "77.0\n",
      "24.5\n",
      "24.5\n",
      "24.5\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import imutils\n",
    "from collections import deque\n",
    "import time \n",
    "# Define the lower and upper boundaries of the \"green\" color in the HSV color space\n",
    "\n",
    "\n",
    "rgb_tennis_ball = np.uint8([[[216, 214, 159]]])\n",
    "\n",
    "# Convert the RGB color to HSV color\n",
    "hsv_tennis_ball = cv2.cvtColor(rgb_tennis_ball, cv2.COLOR_RGB2HSV)\n",
    "\n",
    "# Now we have the HSV value of the tennis ball\n",
    "# We need to define a range around this value for color detection\n",
    "# We can define a reasonable range as 10 for H and 40 for S and V\n",
    "h, s, v = int(hsv_tennis_ball[0][0][0]), int(hsv_tennis_ball[0][0][1]), int(hsv_tennis_ball[0][0][2])\n",
    "lower_bound = (max(0, h - 10), max(0, s - 40), max(0, v - 40))\n",
    "upper_bound = (min(179, h + 10), min(255, s + 40), min(255, v + 40))\n",
    "'''\n",
    "greenLower = (18, 98, 143)\n",
    "greenUpper = (28, 158, 203)\n",
    "'''\n",
    "greenLower = lower_bound\n",
    "greenUpper = upper_bound\n",
    "# Initialize the list of tracked points\n",
    "pts = deque(maxlen=64)\n",
    "\n",
    "# Start the video capture\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Allow the camera to warm up\n",
    "time.sleep(2.0)\n",
    "\n",
    "# Keep looping\n",
    "while True:\n",
    "    # Grab the current frame\n",
    "    _, frame = cap.read()\n",
    "    \n",
    "    # Resize the frame, blur it, and convert it to the HSV color space\n",
    "    frame = imutils.resize(frame, width=600)\n",
    "    blurred = cv2.GaussianBlur(frame, (11, 11), 0)\n",
    "    hsv = cv2.cvtColor(blurred, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "    # Construct a mask for the color \"green\", then perform a series of dilations and erosions to remove any small blobs left in the mask\n",
    "    mask = cv2.inRange(hsv, greenLower, greenUpper)\n",
    "    mask = cv2.erode(mask, None, iterations=2)\n",
    "    mask = cv2.dilate(mask, None, iterations=2)\n",
    "\n",
    "    # Find contours in the mask and initialize the current (x, y) center of the ball\n",
    "    cnts = cv2.findContours(mask.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    cnts = imutils.grab_contours(cnts)\n",
    "    center = None\n",
    "\n",
    "    # Only proceed if at least one contour was found\n",
    "    if len(cnts) > 0:\n",
    "        # Find the largest contour in the mask, then use it to compute the minimum enclosing circle and centroid\n",
    "        c = max(cnts, key=cv2.contourArea)\n",
    "        print(cv2.contourArea(c))\n",
    "        if cv2.contourArea(c) > 200:  # Set your minimum contour area here\n",
    "            ((x, y), radius) = cv2.minEnclosingCircle(c)\n",
    "            M = cv2.moments(c)\n",
    "            center = (int(M[\"m10\"] / M[\"m00\"]), int(M[\"m01\"] / M[\"m00\"]))\n",
    "\n",
    "            # Only proceed if the radius meets a minimum size\n",
    "            if radius > 10:\n",
    "                # Draw the circle and centroid on the frame, then update the list of tracked points\n",
    "\n",
    "                cv2.circle(frame, (int(x), int(y)), int(radius), (0, 255, 255), 2)\n",
    "                cv2.circle(frame, center, 5, (0, 0, 255), -1)\n",
    "\n",
    "    # Update the points queue\n",
    "    pts.appendleft(center)\n",
    "\n",
    "    # Loop over the set of tracked points\n",
    "    for i in range(1, len(pts)):\n",
    "        # If either of the tracked points are None, ignore them\n",
    "        if pts[i - 1] is None or pts[i] is None:\n",
    "            continue\n",
    "\n",
    "        # Otherwise, compute the thickness of the line and draw the connecting lines\n",
    "        thickness = int(np.sqrt(64 / float(i + 1)) * 2.5)\n",
    "        cv2.line(frame, pts[i - 1], pts[i], (0, 0, 255), thickness)\n",
    "\n",
    "    # Show the frame\n",
    "    cv2.imshow(\"Frame\", frame)\n",
    "\n",
    "    # Check for key press to exit\n",
    "    if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "        break\n",
    "\n",
    "# Release the video capture and close all windows\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated greenLower: [ 18  98 143]\n",
      "Updated greenUpper: [ 28 158 203]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Define the HSV color range of the green ball\n",
    "h_range = 5  # Adjust this value as needed\n",
    "s_range = 30  # Adjust this value as needed\n",
    "v_range = 30  # Adjust this value as needed\n",
    "\n",
    "# Convert the average HSV color values to integers\n",
    "avg_color_hsv = np.array([23,128,173], dtype=int)\n",
    "\n",
    "# Calculate the lower and upper boundaries based on the average HSV color values\n",
    "greenLower = np.array([max(0, avg_color_hsv[0] - h_range), max(0, avg_color_hsv[1] - s_range), max(0, avg_color_hsv[2] - v_range)])\n",
    "greenUpper = np.array([min(180, avg_color_hsv[0] + h_range), min(255, avg_color_hsv[1] + s_range), min(255, avg_color_hsv[2] + v_range)])\n",
    "\n",
    "# Print the updated HSV color range for the green ball\n",
    "print(f\"Updated greenLower: {greenLower}\")\n",
    "print(f\"Updated greenUpper: {greenUpper}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ForGPU",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
