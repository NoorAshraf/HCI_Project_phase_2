{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 102ms/step\n",
      "1/1 [==============================] - 0s 114ms/step\n",
      "center\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "center\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "center\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "center\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "center\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "left\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "left\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "left\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "center\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "left\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "center\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "center\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "center\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "center\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "center\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "center\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "center\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "center\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "center\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "center\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "center\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "center\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "center\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "center\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "center\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "center\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "center\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "center\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "center\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "left\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "center\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "center\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "center\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "center\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "center\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "center\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "center\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "center\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "left\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "left\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "left\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "left\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "left\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "left\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "left\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "left\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "left\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "left\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "left\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "left\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "right\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "right\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "right\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "right\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "right\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "center\n"
     ]
    }
   ],
   "source": [
    "import cv2, dlib\n",
    "import numpy as np\n",
    "from imutils import face_utils\n",
    "from tensorflow.keras.models import load_model\n",
    "import winsound\n",
    "\n",
    "IMG_SIZE = (64,56)\n",
    "B_SIZE = (34, 26)\n",
    "margin = 95\n",
    "class_labels = ['center','left', 'right'] \n",
    "detector = dlib.get_frontal_face_detector()\n",
    "predictor = dlib.shape_predictor('shape_predictor_68_face_landmarks.dat')\n",
    "\n",
    "font_letter = cv2.FONT_HERSHEY_PLAIN\n",
    "model = load_model('models/gazev3.1.h5')\n",
    "model_b = load_model('models/blinkdetection.h5')\n",
    "\n",
    "\n",
    "def detect_gaze(eye_img):\n",
    "    pred_l = model.predict(eye_img)\n",
    "    accuracy = int(np.array(pred_l).max() * 100)\n",
    "    gaze = class_labels[np.argmax(pred_l)]\n",
    "    return gaze\n",
    "\n",
    "\n",
    "def detect_blink(eye_img):\n",
    "    pred_B = model_b.predict(eye_img)\n",
    "    status = pred_B[0][0]\n",
    "    status = status*100\n",
    "    status = round(status,3)\n",
    "    return  status\n",
    "\n",
    "   \n",
    "def crop_eye(img, eye_points):\n",
    "    x1, y1 = np.amin(eye_points, axis=0)\n",
    "    x2, y2 = np.amax(eye_points, axis=0)\n",
    "    cx, cy = (x1 + x2) / 2, (y1 + y2) / 2\n",
    "\n",
    "    w = (x2 - x1) * 1.2\n",
    "    h = w * IMG_SIZE[1] / IMG_SIZE[0]\n",
    "\n",
    "    margin_x, margin_y = w / 2, h / 2\n",
    "\n",
    "    min_x, min_y = int(cx - margin_x), int(cy - margin_y)\n",
    "    max_x, max_y = int(cx + margin_x), int(cy + margin_y)\n",
    "\n",
    "    eye_rect = np.rint([min_x, min_y, max_x, max_y]).astype(np.int64)\n",
    "\n",
    "    eye_img = gray[eye_rect[1]:eye_rect[3], eye_rect[0]:eye_rect[2]]\n",
    "\n",
    "    return eye_img, eye_rect\n",
    "\n",
    "# main\n",
    "cap = cv2.VideoCapture(0)\n",
    "# pattern = []\n",
    "# frames = 10\n",
    "# pattern_length = 0\n",
    "frames_to_blink = 6\n",
    "blinking_frames = 0\n",
    "while cap.isOpened():\n",
    "    output = np.zeros((900,820,3), dtype=\"uint8\")\n",
    "    ret, img = cap.read()\n",
    "    img = cv2.flip(img,flipCode = 1)\n",
    "    h,w = (112,128)\t\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "\n",
    "    faces = detector(gray)\n",
    "\n",
    "    for face in faces:\n",
    "        shapes = predictor(gray, face)\n",
    "        \n",
    "\n",
    "        for n in range(36,42):\n",
    "            x= shapes.part(n).x\n",
    "            y = shapes.part(n).y\n",
    "            next_point = n+1\n",
    "            if n==41:\n",
    "                next_point = 36 \n",
    "            \n",
    "            x2 = shapes.part(next_point).x\n",
    "            y2 = shapes.part(next_point).y\n",
    "            cv2.line(img,(x,y),(x2,y2),(0,69,255),2)\n",
    "\n",
    "        for n in range(42,48):\n",
    "            x= shapes.part(n).x\n",
    "            y = shapes.part(n).y\n",
    "            next_point = n+1\n",
    "            if n==47:\n",
    "                next_point = 42 \n",
    "            \n",
    "            x2 = shapes.part(next_point).x\n",
    "            y2 = shapes.part(next_point).y\n",
    "            cv2.line(img,(x,y),(x2,y2),(153,0,153),2)\n",
    "        shapes = face_utils.shape_to_np(shapes)\n",
    "        #~~~~~~~~~~~~~~~~~56,64 EYE IMAGE~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "        eye_img_l, eye_rect_l = crop_eye(gray, eye_points=shapes[36:42])\n",
    "        eye_img_r, eye_rect_r = crop_eye(gray, eye_points=shapes[42:48])\n",
    "        #~~~~~~~~~~~~~~~~FOR THE EYE FINAL_WINDOW~~~~~~~~~~~~~~~~~~~~~~#\n",
    "        eye_img_l_view = cv2.resize(eye_img_l, dsize=(128,112))\n",
    "        eye_img_l_view = cv2.cvtColor(eye_img_l_view,cv2.COLOR_BGR2RGB)\n",
    "        eye_img_r_view = cv2.resize(eye_img_r, dsize=(128,112))\n",
    "        eye_img_r_view = cv2.cvtColor(eye_img_r_view, cv2.COLOR_BGR2RGB)\n",
    "        #~~~~~~~~~~~~~~~~~FOR THE BLINK DETECTION~~~~~~~~~~~~~~~~~~~~~~~\n",
    "        eye_blink_left = cv2.resize(eye_img_l.copy(), B_SIZE)\n",
    "        eye_blink_right = cv2.resize(eye_img_r.copy(), B_SIZE)\n",
    "        eye_blink_left_i = eye_blink_left.reshape((1, B_SIZE[1], B_SIZE[0], 1)).astype(np.float32) / 255.\n",
    "        eye_blink_right_i = eye_blink_right.reshape((1, B_SIZE[1], B_SIZE[0], 1)).astype(np.float32) / 255.\n",
    "        #~~~~~~~~~~~~~~~~FOR THE GAZE DETECTIOM~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "        eye_img_l = cv2.resize(eye_img_l, dsize=IMG_SIZE)\n",
    "        eye_input_g = eye_img_l.copy().reshape((1, IMG_SIZE[1], IMG_SIZE[0], 1)).astype(np.float32) / 255.\n",
    "        #~~~~~~~~~~~~~~~~~~PREDICTION PROCESS~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "        \n",
    "        status_l = detect_blink(eye_blink_left_i)\n",
    "        gaze =  detect_gaze(eye_input_g)\n",
    "        print(gaze)\n",
    "        cv2.imshow('result',img)\n",
    "    if cv2.waitKey(1) == ord('q') : \n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()    \n",
    "# print(pattern)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2, dlib\n",
    "import numpy as np\n",
    "from imutils import face_utils\n",
    "from tensorflow.keras.models import load_model\n",
    "import winsound\n",
    "\n",
    "IMG_SIZE = (64,56)\n",
    "B_SIZE = (34, 26)\n",
    "margin = 95\n",
    "class_labels = ['center','left', 'right'] \n",
    "detector = dlib.get_frontal_face_detector()\n",
    "predictor = dlib.shape_predictor('shape_predictor_68_face_landmarks.dat')\n",
    "\n",
    "font_letter = cv2.FONT_HERSHEY_PLAIN\n",
    "model = load_model('models/gazev3.1.h5')\n",
    "model_b = load_model('models/blinkdetection.h5')\n",
    "\n",
    "\n",
    "def detect_gaze(eye_img):\n",
    "    pred_l = model.predict(eye_img)\n",
    "    accuracy = int(np.array(pred_l).max() * 100)\n",
    "    gaze = class_labels[np.argmax(pred_l)]\n",
    "    return gaze\n",
    "\n",
    "\n",
    "def detect_blink(eye_img):\n",
    "    pred_B = model_b.predict(eye_img)\n",
    "    status = pred_B[0][0]\n",
    "    status = status*100\n",
    "    status = round(status,3)\n",
    "    return  status\n",
    "\n",
    "   \n",
    "def crop_eye(img, eye_points):\n",
    "    x1, y1 = np.amin(eye_points, axis=0)\n",
    "    x2, y2 = np.amax(eye_points, axis=0)\n",
    "    cx, cy = (x1 + x2) / 2, (y1 + y2) / 2\n",
    "\n",
    "    w = (x2 - x1) * 1.2\n",
    "    h = w * IMG_SIZE[1] / IMG_SIZE[0]\n",
    "\n",
    "    margin_x, margin_y = w / 2, h / 2\n",
    "\n",
    "    min_x, min_y = int(cx - margin_x), int(cy - margin_y)\n",
    "    max_x, max_y = int(cx + margin_x), int(cy + margin_y)\n",
    "\n",
    "    eye_rect = np.rint([min_x, min_y, max_x, max_y]).astype(np.int64)\n",
    "\n",
    "    eye_img = gray[eye_rect[1]:eye_rect[3], eye_rect[0]:eye_rect[2]]\n",
    "\n",
    "    return eye_img, eye_rect\n",
    "\n",
    "def get_Eye_Gaze(img):\n",
    "    # pattern = []\n",
    "    # frames = 10\n",
    "    # pattern_length = 0\n",
    "    frames_to_blink = 6\n",
    "    blinking_frames = 0\n",
    "    output = np.zeros((900,820,3), dtype=\"uint8\")\n",
    "    img = cv2.flip(img,flipCode = 1)\n",
    "    h,w = (112,128)\t\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "\n",
    "    faces = detector(gray)\n",
    "\n",
    "    for face in faces:\n",
    "        shapes = predictor(gray, face)\n",
    "        \n",
    "\n",
    "        for n in range(36,42):\n",
    "            x= shapes.part(n).x\n",
    "            y = shapes.part(n).y\n",
    "            next_point = n+1\n",
    "            if n==41:\n",
    "                next_point = 36 \n",
    "            \n",
    "            x2 = shapes.part(next_point).x\n",
    "            y2 = shapes.part(next_point).y\n",
    "            cv2.line(img,(x,y),(x2,y2),(0,69,255),2)\n",
    "\n",
    "        for n in range(42,48):\n",
    "            x= shapes.part(n).x\n",
    "            y = shapes.part(n).y\n",
    "            next_point = n+1\n",
    "            if n==47:\n",
    "                next_point = 42 \n",
    "            \n",
    "            x2 = shapes.part(next_point).x\n",
    "            y2 = shapes.part(next_point).y\n",
    "            cv2.line(img,(x,y),(x2,y2),(153,0,153),2)\n",
    "        shapes = face_utils.shape_to_np(shapes)\n",
    "        #~~~~~~~~~~~~~~~~~56,64 EYE IMAGE~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "        eye_img_l, eye_rect_l = crop_eye(gray, eye_points=shapes[36:42])\n",
    "        eye_img_r, eye_rect_r = crop_eye(gray, eye_points=shapes[42:48])\n",
    "        #~~~~~~~~~~~~~~~~FOR THE EYE FINAL_WINDOW~~~~~~~~~~~~~~~~~~~~~~#\n",
    "        eye_img_l_view = cv2.resize(eye_img_l, dsize=(128,112))\n",
    "        eye_img_l_view = cv2.cvtColor(eye_img_l_view,cv2.COLOR_BGR2RGB)\n",
    "        eye_img_r_view = cv2.resize(eye_img_r, dsize=(128,112))\n",
    "        eye_img_r_view = cv2.cvtColor(eye_img_r_view, cv2.COLOR_BGR2RGB)\n",
    "        #~~~~~~~~~~~~~~~~~FOR THE BLINK DETECTION~~~~~~~~~~~~~~~~~~~~~~~\n",
    "        eye_blink_left = cv2.resize(eye_img_l.copy(), B_SIZE)\n",
    "        eye_blink_right = cv2.resize(eye_img_r.copy(), B_SIZE)\n",
    "        eye_blink_left_i = eye_blink_left.reshape((1, B_SIZE[1], B_SIZE[0], 1)).astype(np.float32) / 255.\n",
    "        eye_blink_right_i = eye_blink_right.reshape((1, B_SIZE[1], B_SIZE[0], 1)).astype(np.float32) / 255.\n",
    "        #~~~~~~~~~~~~~~~~FOR THE GAZE DETECTIOM~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "        eye_img_l = cv2.resize(eye_img_l, dsize=IMG_SIZE)\n",
    "        eye_input_g = eye_img_l.copy().reshape((1, IMG_SIZE[1], IMG_SIZE[0], 1)).astype(np.float32) / 255.\n",
    "        #~~~~~~~~~~~~~~~~~~PREDICTION PROCESS~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "        \n",
    "        status_l = detect_blink(eye_blink_left_i)\n",
    "        gaze =  detect_gaze(eye_input_g)\n",
    "        return gaze\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ForGPU",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
